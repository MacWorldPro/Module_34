{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1+wEy83wyoKRJ2flAZoEM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MacWorldPro/Module_34/blob/main/Module56.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1:\n",
        "\n",
        "Data encoding is a method which is done while feature engineering, during which a categorical data is converted into numercial data.\n",
        "It is helpful while training ML models as all the things are mathematical and mathematics is all about numbers."
      ],
      "metadata": {
        "id": "FDRx5JQ0vLzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2:\n",
        "\n",
        "Nominal encoding is used in the categorical variable which do not follow rank/order."
      ],
      "metadata": {
        "id": "AXM51MFPv3nA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3:\n",
        "\n",
        "Nominal encoding is preferred over one-hot encoding when dealing with categorical variables having many unique categories, avoiding high-dimensional feature spaces. For example, in NLP tasks with vast vocabularies, nominal encoding methods like frequency-based or target encoding are used to represent words, ensuring manageable feature dimensions while retaining categorical information."
      ],
      "metadata": {
        "id": "Wlo_FkurwKzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4:\n",
        "\n",
        "For a dataset with only 5 unique values, I'd choose one-hot encoding. It's simple and efficient, creating binary features for each category. This maintains the integrity of the categorical data without increasing dimensionality significantly. It's suitable for small sets of categories like this, ensuring clear representation for machine learning algorithms."
      ],
      "metadata": {
        "id": "2S1XD4S3wqVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5:\n",
        "\n",
        "It will be based on number of unique values present in the categorical column. Considering all the every row of categorical column is unique, so in total 2000."
      ],
      "metadata": {
        "id": "HtGsvyNNxBwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6:\n",
        "\n",
        "For a dataset with categorical variables like species, habitat, and diet for animals, I'd opt for a combination of nominal encoding techniques. Label encoding could be suitable for ordinal categories like diet types, while one-hot encoding might be preferable for species and habitat due to their non-ordinal nature, preserving categorical distinctions without imposing an order."
      ],
      "metadata": {
        "id": "aR__29GQxe6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7:\n",
        "\n",
        "For the given dataset:\n",
        "\n",
        "1. **Gender**: Use binary encoding (0 for female, 1 for male).\n",
        "2. **Contract type**: Use one-hot encoding for each contract type.\n",
        "3. No encoding needed for **age**, **monthly charges**, and **tenure** as they are numerical.\n",
        "\n",
        "Binary encoding reduces dimensionality for gender, while one-hot ensures distinction for contract types. This maintains data integrity for accurate churn prediction."
      ],
      "metadata": {
        "id": "tLnllI_Nxw2Q"
      }
    }
  ]
}